{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a13813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from itertools import permutations, combinations\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "s=set(stopwords.words('english'))\n",
    "\n",
    "start = 'C:/Users/gony/Desktop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef2a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return list(filter(lambda w: not w.lower() in s,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ddd93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nodes_edges(data):\n",
    "    # creating emtpy df\n",
    "    output_graph = pd.DataFrame(columns=['source', 'target'])\n",
    "    \n",
    "    # iterating over each row \n",
    "    for i, row in tqdm(data.iterrows()):\n",
    "        temp = row['words_sentences']\n",
    "        \n",
    "        # iterating over each sentence, since we are creating an each between two words\n",
    "        # if the appeared together in the same sentence\n",
    "        for sen in temp:\n",
    "            \n",
    "            # creates list of permutation of 2 for all the words in the sentence\n",
    "            temp_df = pd.DataFrame(data =list(combinations([x.lower() for x in sen], 2)), columns=['source', 'target'])\n",
    "            output_graph = output_graph.append(temp_df, ignore_index = True)\n",
    "    \n",
    "#     # groupby source and target and count all the apperance\n",
    "#     output_graph['count']=output_graph.groupby('source')['target'].transform('count')#all rows ; \n",
    "    count_series = output_graph.groupby(['source', 'target']).size()\n",
    "\n",
    "#     # remove duplicates\n",
    "#     output_graph.drop_duplicates(inplace=True)\n",
    "    new_df = count_series.to_frame(name = 'weight').reset_index()\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e84bf297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [00:51,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [01:30,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [01:02,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [01:10,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "110it [02:06,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77it [01:23,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "115it [02:13,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [01:06,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [02:03,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [01:12,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [02:25,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:53,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [01:55,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77it [01:05,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [01:25,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [01:12,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "93it [01:31,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [00:57,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:17,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:59,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [01:24,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:55,  1.52it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:18,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "93it [01:03,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "117it [01:14,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:37,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:04,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:27,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [01:05,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [01:02,  1.15it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [00:30,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [01:16,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [01:05,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [01:12,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [01:07,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [01:04,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [01:10,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [01:10,  1.15it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [00:35,  2.53it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67it [00:21,  3.14it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:34,  2.92it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [00:15,  4.04it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:21,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [00:47,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [00:25,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:40,  2.54it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:19,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [00:40,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [00:56,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [00:40,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:53,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "95it [00:31,  3.04it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "106it [00:39,  2.70it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:22,  3.55it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:24,  2.65it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:26,  3.86it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:16,  1.66it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [00:23,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82it [00:49,  1.66it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.09.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [00:12,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.10.2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:34,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "path = start+'data/9_11_2001.zip'\n",
    "with ZipFile(path, \"r\") as zip_ref:\n",
    "    for f in zip_ref.namelist():\n",
    "        print(f)\n",
    "        day = pd.read_csv(zip_ref.open(f))\n",
    "\n",
    "        day['temp'] = day.apply(lambda row: re.sub(r'\\b[A-Z]+\\b', '', row['text']), axis=1)\n",
    "        # split each text by sentences, receiving list of strings each string is a sentence\n",
    "        # in the original text.\n",
    "        day['sentences'] = day.temp.str.split('.')\n",
    "\n",
    "        # removing punctiuation marks from each sentence\n",
    "        day['sentences'] = [[s.translate(str.maketrans('', '', string.punctuation)) for s in t] for t in day.sentences]\n",
    "\n",
    "        # split each sentence to words, reveiving list of lists, \n",
    "        # each sublist has all the words in  original sentence after removing stopwords\n",
    "        day['words_sentences'] =[[list(filter(lambda w: not w.lower() in s,sen.split())) for sen in text] for text in day.sentences]\n",
    "\n",
    "        # splitting all words in text to a list of words removing stopwords\n",
    "        # (i forgot to remove punctuation marks but for now we aren't using this so i'll fix in later)\n",
    "        day['words_text'] = [remove_stopwords(t.split()) for t in day.temp]\n",
    "    #     print(Counter(day['words_text'][0]).most_common(5))\n",
    "    #     print(day['sentences'][0][0])\n",
    "    #     break\n",
    "        create_nodes_edges(day).to_csv(start+'data/new/9_11_2001/nodes' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67a4b83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                                url channel.name  \\\n0       11995  http://transcripts.cnn.com/TRANSCRIPTS/0109/01...          WWW   \n\n       program.name  uid  duration    year  month  date   time timezone  path  \\\n0  CNN CAPITAL GANG  NaN       NaN  2001.0    9.0   1.0  19:00       ET   NaN   \n\n   wordcount                                            subhead  \\\n0        NaN  Gary Bauer Discusses Mideast Policy; Michael P...   \n\n                                                text  \\\n0  ANNOUNCER:  From Washington: the CAPITAL GANG....   \n\n                                                temp  \\\n0  :  From Washington: the  .       , :  Welcome ...   \n\n                                           sentences  \\\n0  [  From Washington the  ,           Welcome to...   \n\n                                     words_sentences  \\\n0  [[Washington], [Welcome], [Mark, Shields, Al, ...   \n\n                                          words_text  \n0  [ANNOUNCER:, Washington:, CAPITAL, GANG., MARK...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>url</th>\n      <th>channel.name</th>\n      <th>program.name</th>\n      <th>uid</th>\n      <th>duration</th>\n      <th>year</th>\n      <th>month</th>\n      <th>date</th>\n      <th>time</th>\n      <th>timezone</th>\n      <th>path</th>\n      <th>wordcount</th>\n      <th>subhead</th>\n      <th>text</th>\n      <th>temp</th>\n      <th>sentences</th>\n      <th>words_sentences</th>\n      <th>words_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11995</td>\n      <td>http://transcripts.cnn.com/TRANSCRIPTS/0109/01...</td>\n      <td>WWW</td>\n      <td>CNN CAPITAL GANG</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2001.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>19:00</td>\n      <td>ET</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gary Bauer Discusses Mideast Policy; Michael P...</td>\n      <td>ANNOUNCER:  From Washington: the CAPITAL GANG....</td>\n      <td>:  From Washington: the  .       , :  Welcome ...</td>\n      <td>[  From Washington the  ,           Welcome to...</td>\n      <td>[[Washington], [Welcome], [Mark, Shields, Al, ...</td>\n      <td>[ANNOUNCER:, Washington:, CAPITAL, GANG., MARK...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b182bdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03.2003.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:06,  1.13s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_25380\\4164260927.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m             \u001B[0mday\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'words_sentences'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0msen\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mtext\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mday\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentences\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m             \u001B[0mday\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'words_text'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mremove_stopwords\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mday\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m             \u001B[0mcreate_nodes_edges\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mday\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m'data/new/iraq_3_20_2003/nodes'\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_25380\\650663668.py\u001B[0m in \u001B[0;36mcreate_nodes_edges\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m     13\u001B[0m             \u001B[1;31m# creates list of permutation of 2 for all the words in the sentence\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m             \u001B[0mtemp_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcombinations\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msen\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'source'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'target'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m             \u001B[0moutput_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moutput_graph\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtemp_df\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;31m#     # groupby source and target and count all the apperance\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gony\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mappend\u001B[1;34m(self, other, ignore_index, verify_integrity, sort)\u001B[0m\n\u001B[0;32m   7749\u001B[0m             \u001B[0mignore_index\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mignore_index\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   7750\u001B[0m             \u001B[0mverify_integrity\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mverify_integrity\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 7751\u001B[1;33m             \u001B[0msort\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msort\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   7752\u001B[0m         )\n\u001B[0;32m   7753\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gony\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001B[0m in \u001B[0;36mconcat\u001B[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[0;32m    285\u001B[0m     )\n\u001B[0;32m    286\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 287\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    288\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    289\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gony\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001B[0m in \u001B[0;36mget_result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    501\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    502\u001B[0m             new_data = concatenate_block_managers(\n\u001B[1;32m--> 503\u001B[1;33m                 \u001B[0mmgrs_indexers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnew_axes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconcat_axis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbm_axis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    504\u001B[0m             )\n\u001B[0;32m    505\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gony\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001B[0m in \u001B[0;36mconcatenate_block_managers\u001B[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001B[0m\n\u001B[0;32m     62\u001B[0m                 \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m             \u001B[0mb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_block_same_class\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplacement\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mplacement\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m         \u001B[1;32melif\u001B[0m \u001B[0m_is_uniform_join_units\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjoin_units\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m             \u001B[0mblk\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjoin_units\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m             \u001B[0mvals\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mju\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mju\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mjoin_units\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gony\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001B[0m in \u001B[0;36m_is_uniform_join_units\u001B[1;34m(join_units)\u001B[0m\n\u001B[0;32m    478\u001B[0m         \u001B[1;31m# no blocks that would get missing values (can lead to type upcasts)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    479\u001B[0m         \u001B[1;31m# unless we're an extension dtype.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 480\u001B[1;33m         \u001B[0mall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mnot\u001B[0m \u001B[0mju\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_na\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mju\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_extension\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mju\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mjoin_units\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    481\u001B[0m         \u001B[1;32mand\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    482\u001B[0m         \u001B[1;31m# no blocks with indexers (as then the dimensions do not fit)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gony\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001B[0m in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    478\u001B[0m         \u001B[1;31m# no blocks that would get missing values (can lead to type upcasts)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    479\u001B[0m         \u001B[1;31m# unless we're an extension dtype.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 480\u001B[1;33m         \u001B[0mall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mnot\u001B[0m \u001B[0mju\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_na\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mju\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_extension\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mju\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mjoin_units\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    481\u001B[0m         \u001B[1;32mand\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    482\u001B[0m         \u001B[1;31m# no blocks with indexers (as then the dimensions do not fit)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.CachedProperty.__get__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gony\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001B[0m in \u001B[0;36mis_na\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    226\u001B[0m         \u001B[0mchunk_len\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtotal_len\u001B[0m \u001B[1;33m//\u001B[0m \u001B[1;36m40\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    227\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtotal_len\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mchunk_len\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 228\u001B[1;33m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues_flat\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mchunk_len\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    229\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    230\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\gony\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_methods.py\u001B[0m in \u001B[0;36m_all\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m     61\u001B[0m     \u001B[1;31m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mwhere\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mumr_all\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mumr_all\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwhere\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mwhere\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "path = start+'data/iraq_3_20_2003.zip'\n",
    "with ZipFile(path, \"r\") as zip_ref:\n",
    "    for f in zip_ref.namelist():\n",
    "        if f[:-4] < '3.04.2003' and f[:-4]>'18.03.2003':\n",
    "            print(f)\n",
    "            day = pd.read_csv(zip_ref.open(f))\n",
    "            day['sentences'] = day.text.str.split('.')\n",
    "            day = day[day['sentences'].notna()]\n",
    "            day['sentences'] = [[s.translate(str.maketrans('', '', string.punctuation)) for s in t] for t in day.sentences]\n",
    "            day['words_sentences'] =[[list(filter(lambda w: not w.lower() in s,sen.split())) for sen in text] for text in day.sentences]\n",
    "            day['words_text'] = [remove_stopwords(t.split()) for t in day.text]\n",
    "            create_nodes_edges(day).to_csv(start+'data/new/iraq_3_20_2003/nodes' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42137d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.09.2005.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [01:21,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "path = start + 'data/katrina_08_2005.zip'\n",
    "with ZipFile(path, \"r\") as zip_ref:\n",
    "    for f in zip_ref.namelist():\n",
    "        if f[:-4] < '7.09.2005' and f[:-4]>'17.08.2005':\n",
    "            print(f)\n",
    "            day = pd.read_csv(zip_ref.open(f))\n",
    "            day['sentences'] = day.text.str.split('.')\n",
    "            day = day[day['sentences'].notna()]\n",
    "            day['sentences'] = [[s.translate(str.maketrans('', '', string.punctuation)) for s in t] for t in day.sentences]\n",
    "            day['words_sentences'] =[[list(filter(lambda w: not w.lower() in s,sen.split())) for sen in text] for text in day.sentences]\n",
    "            day['words_text'] = [remove_stopwords(t.split()) for t in day.text]\n",
    "            create_nodes_edges(day).to_csv(start+'data/new/katrina_08_2005/nodes' + f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cad9efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:59,  3.51s/it]\n",
      "26it [01:55,  4.45s/it]\n",
      "28it [02:26,  5.23s/it]\n",
      "28it [02:01,  4.32s/it]\n",
      "26it [01:57,  4.51s/it]\n",
      "20it [01:00,  3.04s/it]\n",
      "14it [00:42,  3.06s/it]\n",
      "26it [02:17,  5.27s/it]\n",
      "26it [01:48,  4.17s/it]\n",
      "37it [03:26,  5.57s/it]\n",
      "28it [01:55,  4.11s/it]\n",
      "26it [01:45,  4.05s/it]\n",
      "27it [01:57,  4.36s/it]\n",
      "27it [01:41,  3.76s/it]\n",
      "19it [00:46,  2.43s/it]\n",
      "28it [01:57,  4.21s/it]\n",
      "27it [01:45,  3.90s/it]\n",
      "26it [01:51,  4.29s/it]\n",
      "20it [00:52,  2.62s/it]\n",
      "14it [00:35,  2.50s/it]\n",
      "26it [01:46,  4.10s/it]\n"
     ]
    }
   ],
   "source": [
    "path = start+'data/binladin_02_05_2011/'\n",
    "for f in os.listdir(path):\n",
    "    day = pd.read_csv(path+f)\n",
    "    day['sentences'] = day.text.str.split('.')\n",
    "    day = day[day['sentences'].notna()]\n",
    "    day['sentences'] = [[s.translate(str.maketrans('', '', string.punctuation)) for s in t] for t in day.sentences]\n",
    "    day['words_sentences'] =[[list(filter(lambda w: not w.lower() in s,sen.split())) for sen in text] for text in day.sentences]\n",
    "    day['words_text'] = [remove_stopwords(t.split()) for t in day.text]\n",
    "    create_nodes_edges(day).to_csv(start+'data/new/binladin_02_05_2011/nodes' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b126fb1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [01:23,  2.13s/it]\n",
      "40it [01:20,  2.00s/it]\n",
      "19it [00:37,  1.97s/it]\n",
      "14it [00:22,  1.60s/it]\n",
      "40it [01:47,  2.69s/it]\n",
      "47it [02:28,  3.15s/it]\n",
      "42it [01:51,  2.66s/it]\n",
      "46it [02:55,  3.81s/it]\n",
      "43it [03:36,  5.03s/it]\n",
      "22it [01:23,  3.82s/it]\n",
      "17it [00:56,  3.30s/it]\n",
      "41it [02:15,  3.31s/it]\n",
      "41it [02:12,  3.23s/it]\n",
      "39it [02:02,  3.14s/it]\n",
      "39it [02:18,  3.55s/it]\n",
      "38it [01:54,  3.02s/it]\n",
      "20it [00:57,  2.88s/it]\n",
      "14it [00:40,  2.88s/it]\n",
      "39it [02:12,  3.40s/it]\n",
      "39it [02:20,  3.61s/it]\n"
     ]
    }
   ],
   "source": [
    "path = start+'data/boston_15_04_2013/'\n",
    "for f in os.listdir(path):\n",
    "    day = pd.read_csv(path+f)\n",
    "    day['sentences'] = day.text.str.split('.')\n",
    "    day = day[day['sentences'].notna()]\n",
    "    day['sentences'] = [[s.translate(str.maketrans('', '', string.punctuation)) for s in t] for t in day.sentences]\n",
    "    day['words_sentences'] =[[list(filter(lambda w: not w.lower() in s,sen.split())) for sen in text] for text in day.sentences]\n",
    "    day['words_text'] = [remove_stopwords(t.split()) for t in day.text]\n",
    "    create_nodes_edges(day).to_csv(start+'data/new/boston_15_04_2013/nodes' + f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}